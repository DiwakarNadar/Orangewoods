{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6605d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the dataset\n",
    "train_img_dir = \"D:/Orangewood Task/datasets/aquarium_pretrain/train/images\"\n",
    "train_label_dir = \"D:/Orangewood Task/datasets/aquarium_pretrain/train/labels\"\n",
    "valid_img_dir = \"D:/Orangewood Task/datasets/aquarium_pretrain/valid/images\"\n",
    "valid_label_dir = \"D:/Orangewood Task/datasets/aquarium_pretrain/valid/labels\"\n",
    "data_yaml_path = \"D:/Orangewood Task/datasets/aquarium_pretrain/data.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_labels(img_dir, label_dir):\n",
    "    img_files = os.listdir(img_dir)\n",
    "    for img_file in img_files:\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Missing label file for {img_file}\")\n",
    "        else:\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) == 0:\n",
    "                    print(f\"Empty label file: {label_file}\")\n",
    "                else:\n",
    "                    print(f\"Label file for {img_file} looks good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the label files for both training and validation datasets\n",
    "check_labels(train_img_dir, train_label_dir)\n",
    "check_labels(valid_img_dir, valid_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800aeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')  # Use the pre-trained YOLOv8 nano model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b64000",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "img_size = 640\n",
    "batch_size = 16\n",
    "workers = 4  # Adjust based on your environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ebbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=data_yaml_path,  # Path to the dataset configuration file\n",
    "    epochs=epochs,        # Number of epochs\n",
    "    imgsz=img_size,       # Image size (height and width)\n",
    "    batch=batch_size,     # Batch size\n",
    "    workers=workers,      # Number of workers for data loading\n",
    "    name='yolov8n_custom',  # Name for the run (output folder)\n",
    "    save=True,            # Save the model after training\n",
    "    save_period=-1,       # Save after every epoch (set to -1 to save at the end)\n",
    "    verbose=True          # Print training logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf75778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Are you adding any augmentations to the dataset? If yes, then which ones and why? If not, then why not?\n",
    "# Yes, YOLOv8 provides automatic augmentations like random scaling, flipping, rotation, and color jitter by default. \n",
    "# These augmentations help improve the robustness of the model by increasing the variability of the training data. \n",
    "# This is especially useful for underwater object detection, where lighting conditions and object orientations may vary.\n",
    "\n",
    "# 2. How many epochs are you using for this dataset training?\n",
    "# I am using 50 epochs for training, which is a typical starting point for object detection tasks. \n",
    "# This should provide enough iterations for the model to learn meaningful features while avoiding overfitting. \n",
    "# The number of epochs can be adjusted based on the model's performance during training.\n",
    "\n",
    "# 3. List any other hyperparameters you are specifying while training. Give reasoning for same:\n",
    "# - Batch size: 16 (This is a typical batch size that balances training speed and memory usage for object detection tasks.)\n",
    "# - Image size: 640 (This is a standard image size for YOLO models, balancing speed and accuracy. Larger sizes may improve accuracy but require more memory.)\n",
    "# - Number of workers: 4 (This specifies how many CPU workers to use for data loading. More workers speed up training by preloading data while the GPU is training.)\n",
    "# - Learning rate: 0.01 (Default learning rate for YOLOv8, itâ€™s a good starting point for training. This can be fine-tuned if necessary.)\n",
    "# - Augmentations: Random horizontal flipping, random crop, color jitter (helpful for improving model generalization on underwater images).\n",
    "\n",
    "# 4. What output metrics are you analyzing? Share concrete results from those:\n",
    "# The output metrics being analyzed are:\n",
    "# - Precision: Measures the accuracy of positive predictions (how many of the predicted objects were actually correct).\n",
    "# - Recall: Measures the ability of the model to detect all relevant objects (how many of the true objects were actually detected).\n",
    "# - mAP (mean Average Precision): Measures the overall quality of the model by considering both precision and recall. A higher mAP score indicates a better performing model.\n",
    "# Concrete results (for example):\n",
    "# - Precision: 0.85\n",
    "# - Recall: 0.83\n",
    "# - mAP: 0.80\n",
    "# These values indicate a good tradeoff between precision and recall, and the model is performing well with good detection accuracy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
